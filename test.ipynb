{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I heard that you taught him how to do a show.',\n",
       " \"Of course, he's been on many TV shows and TV programs.\",\n",
       " 'But on the internet,',\n",
       " 'the communication is different.',\n",
       " 'Communication is really important.',\n",
       " 'He always looks at the camera.',\n",
       " 'But on the internet, you have to look at the screen.',\n",
       " 'Right, the comments.',\n",
       " \"And on the live show, there's a donation system.\",\n",
       " \"That's a must.\",\n",
       " 'You have to listen to the song.',\n",
       " 'You have to listen to the song.',\n",
       " 'Thank you, Nugun.',\n",
       " 'You have to react to the song.',\n",
       " \"I'll leave it.\",\n",
       " \"It's good to get paid a lot.\",\n",
       " \"That's one thing.\",\n",
       " 'There are live comments.',\n",
       " \"There's a tip to read the comments.\",\n",
       " 'There will be a lot of comments.',\n",
       " \"It's going to be over soon.\",\n",
       " \"I've seen 4,000 to 5,000 comments.\",\n",
       " 'How do you read this?',\n",
       " 'You can read the comments of people like Kim Gu-ra.',\n",
       " 'There are people who always talk about the 12th group.',\n",
       " 'The cynical people.',\n",
       " \"I don't leave comments.\",\n",
       " \"That's the way you talk.\",\n",
       " 'You leave comments.',\n",
       " \"I don't leave comments.\",\n",
       " 'There are people who write comments.',\n",
       " 'They write funny comments.',\n",
       " 'Then, it becomes a Tiki-taka.',\n",
       " 'If you focus on those people, you can have fun.',\n",
       " \"It's been so fast.\",\n",
       " 'How do you catch it?',\n",
       " 'It improves your physical ability.',\n",
       " \"We're just talking about physical ability.\",\n",
       " \"I'm the only one who sees it on the screen.\",\n",
       " \"It's fast.\",\n",
       " 'The problem is that Won is here.',\n",
       " \"I can't see it, so I keep looking at it.\",\n",
       " 'Okhaek has a special skill that makes him excited.',\n",
       " 'There should be one.',\n",
       " \"I didn't make myself.\",\n",
       " \"I didn't sit down.\",\n",
       " \"It's my knee dance.\",\n",
       " 'This is a signature dance.',\n",
       " 'Donations are based on donations.',\n",
       " 'This is the highest price.',\n",
       " \"Let's see it.\",\n",
       " \"I can't believe you're watching this.\",\n",
       " \"Let's go for the highest price.\",\n",
       " \"It's 1 million won.\",\n",
       " \"It's 1 million won.\",\n",
       " \"It's 1 million won.\",\n",
       " \"It's 1 million won.\",\n",
       " 'How can this be?',\n",
       " \"It's my first time watching it.\",\n",
       " \"It's an honor.\",\n",
       " 'You have to watch it yourself.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "I heard that you taught him how to do a show.\n",
    " Of course, he's been on many TV shows and TV programs.\n",
    " But on the internet,\n",
    " the communication is different.\n",
    " Communication is really important.\n",
    " He always looks at the camera.\n",
    " But on the internet, you have to look at the screen.\n",
    " Right, the comments.\n",
    " And on the live show, there's a donation system.\n",
    " That's a must.\n",
    " You have to listen to the song.\n",
    " You have to listen to the song.\n",
    " Thank you, Nugun.\n",
    " You have to react to the song.\n",
    " I'll leave it.\n",
    " It's good to get paid a lot.\n",
    " That's one thing.\n",
    " There are live comments.\n",
    " There's a tip to read the comments.\n",
    " There will be a lot of comments.\n",
    " It's going to be over soon.\n",
    " I've seen 4,000 to 5,000 comments.\n",
    " How do you read this?\n",
    " You can read the comments of people like Kim Gu-ra.\n",
    " There are people who always talk about the 12th group.\n",
    " The cynical people.\n",
    " I don't leave comments.\n",
    " That's the way you talk.\n",
    " You leave comments.\n",
    " I don't leave comments.\n",
    " There are people who write comments.\n",
    " They write funny comments.\n",
    " Then, it becomes a Tiki-taka.\n",
    " If you focus on those people, you can have fun.\n",
    " It's been so fast.\n",
    " How do you catch it?\n",
    " It improves your physical ability.\n",
    " We're just talking about physical ability.\n",
    " I'm the only one who sees it on the screen.\n",
    " It's fast.\n",
    " The problem is that Won is here.\n",
    " I can't see it, so I keep looking at it.\n",
    " Okhaek has a special skill that makes him excited.\n",
    " There should be one.\n",
    " I didn't make myself.\n",
    " I didn't sit down.\n",
    " It's my knee dance.\n",
    " This is a signature dance.\n",
    " Donations are based on donations.\n",
    " This is the highest price.\n",
    " Let's see it.\n",
    " I can't believe you're watching this.\n",
    " Let's go for the highest price.\n",
    " It's 1 million won.\n",
    " It's 1 million won.\n",
    " It's 1 million won.\n",
    " It's 1 million won.\n",
    " How can this be?\n",
    " It's my first time watching it.\n",
    " It's an honor.\n",
    " You have to watch it yourself.\n",
    "\"\"\"\n",
    "text = text.split('\\n')\n",
    "text = [t.strip() for t in text if t]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>model_path = <span style=\"color: #808000; text-decoration-color: #808000\">'cardiffnlp/twitter-roberta-base-sentiment-latest'</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>sentiment_task = pipeline(<span style=\"color: #808000; text-decoration-color: #808000\">\"sentiment-analysis\"</span>, model=model_path, tokenizer=model_path)      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> t <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> text:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>6 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>sentiment.append(sentiment_task(t)[<span style=\"color: #808000; text-decoration-color: #808000\">'label'</span>])                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7 </span>sentiment                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span>list indices must be integers or slices, not str\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0mmodel_path = \u001b[33m'\u001b[0m\u001b[33mcardiffnlp/twitter-roberta-base-sentiment-latest\u001b[0m\u001b[33m'\u001b[0m                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0msentiment_task = pipeline(\u001b[33m\"\u001b[0m\u001b[33msentiment-analysis\u001b[0m\u001b[33m\"\u001b[0m, model=model_path, tokenizer=model_path)      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[94mfor\u001b[0m t \u001b[95min\u001b[0m text:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m6 \u001b[2m│   \u001b[0msentiment.append(sentiment_task(t)[\u001b[33m'\u001b[0m\u001b[33mlabel\u001b[0m\u001b[33m'\u001b[0m])                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0msentiment                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m8 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0mlist indices must be integers or slices, not str\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sentiment = []\n",
    "model_path = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path)\n",
    "for t in text:\n",
    "    sentiment.append(sentiment_task(t)[0]['label'])\n",
    "sentiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d92da0a1b2a9422f3c47c40724438aa15fd669204e554153def5387194ea7e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
